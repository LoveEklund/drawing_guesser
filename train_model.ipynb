{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json \n",
    "import numpy as np\n",
    "import os \n",
    "from model.model import get_model\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(folder, n_per_class = 10_000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    label_mapping = {}\n",
    "    files = os.listdir(folder)\n",
    "    for file in files:\n",
    "        label = len(label_mapping)\n",
    "        print(file)\n",
    "        label_mapping[label] = file.split(\"_\")[-1].split(\".\")[0]\n",
    "        tmp_data = np.load(os.path.join(folder,file), encoding='latin1', allow_pickle=True)\n",
    "        for data_point in tmp_data[:n_per_class]:\n",
    "            data.append(np.array(data_point).reshape((28,28)))\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(labels) , label_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_numpy_bitmap_ant.npy\n",
      "full_numpy_bitmap_arm.npy\n",
      "full_numpy_bitmap_axe.npy\n",
      "full_numpy_bitmap_bee.npy\n",
      "full_numpy_bitmap_car.npy\n",
      "full_numpy_bitmap_cat.npy\n",
      "full_numpy_bitmap_cup.npy\n",
      "full_numpy_bitmap_ear.npy\n",
      "full_numpy_bitmap_key.npy\n",
      "full_numpy_bitmap_pig.npy\n",
      "full_numpy_bitmap_sun.npy\n"
     ]
    }
   ],
   "source": [
    "# You can get data by downloading some files from here and put them in the data folder\n",
    "#https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap;tab=objects?prefix=&forceOnObjectsSortingFiltering=false\n",
    "\n",
    "data, labels, label_mapping = read_data(\"Data\", n_per_class=70_000)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element: 0, Count: 70000\n",
      "Element: 1, Count: 70000\n",
      "Element: 2, Count: 70000\n",
      "Element: 3, Count: 70000\n",
      "Element: 4, Count: 70000\n",
      "Element: 5, Count: 70000\n",
      "Element: 6, Count: 70000\n",
      "Element: 7, Count: 70000\n",
      "Element: 8, Count: 70000\n",
      "Element: 9, Count: 70000\n",
      "Element: 10, Count: 70000\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter# Count occurrences of each unique element\n",
    "element_counts = Counter(labels)\n",
    "\n",
    "# Print the counts\n",
    "for element, count in element_counts.items():\n",
    "    print(f\"Element: {element}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(len(label_mapping),dropout_rate=0, l2_lambda=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshaped = x_train.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalize the data values to range [0, 1]\n",
    "x_train_normalized = x_train_reshaped / 255.0\n",
    "\n",
    "x_val_reshaped = x_val.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalize the data values to range [0, 1]\n",
    "x_val_normalized = x_val_reshaped / 255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(x_train_normalized, y_train, epochs=10, batch_size=128, validation_data=(x_val_normalized, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(x_val_normalized)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) \n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "((cm / cm.sum(axis=1, keepdims=True))*10000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model/model.h5')\n",
    "\n",
    "directory = \"model\"\n",
    "# Save dictionary using pickle\n",
    "with open(os.path.join(directory, 'label_mapping.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_mapping, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drawing_recog-AEnQ1kVC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
